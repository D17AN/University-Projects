{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27b8697c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network 1 \n",
      "Test loss: 0.07\n",
      "Accuracy: 87.50%\n",
      "Predictions: [-0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "Network 2 \n",
      "Test loss: 0.00\n",
      "Accuracy: 100.00%\n",
      "Predictions: [0.0, 0.0, -0.0, 1.0, 0.0, 1.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "Network 3 \n",
      "Test loss: 0.00\n",
      "Accuracy: 100.00%\n",
      "Predictions: [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "Network 2: \n",
      "fc1.weight Parameter containing:\n",
      "tensor([[-4.1399, -4.1347],\n",
      "        [-2.9496, -2.9468],\n",
      "        [ 2.7786,  2.7535]], requires_grad=True)\n",
      "fc1.bias Parameter containing:\n",
      "tensor([ 5.9898,  0.7628, -0.6393], requires_grad=True)\n",
      "fc2.weight Parameter containing:\n",
      "tensor([[-1.3350,  0.1467, -0.1687],\n",
      "        [ 1.5553, -1.7784,  0.3173]], requires_grad=True)\n",
      "fc2.bias Parameter containing:\n",
      "tensor([ 1.2899, -0.4482], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Define the binary addition database\n",
    "x_train = torch.Tensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_train = torch.Tensor([[0, 0], [0, 1], [0, 1], [1, 0]])\n",
    "\n",
    "# Network 1\n",
    "# Define the model architecture\n",
    "# Activation function: sigmoid\n",
    "# Arhitecture: 2 input neurons, 2 hidden neurons, 2 output neuron\n",
    "# Loss function: Mean squared error\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(2, 2)),          \n",
    "            ('sigmoid1', nn.Sigmoid()),          \n",
    "            ('fc2', nn.Linear(2, 2)),          \n",
    "            ('linear1', nn.Identity())        ]))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(1000):\n",
    "  # Forward pass\n",
    "  y_pred = model1(x_train)\n",
    "\n",
    "  # Compute loss\n",
    "  loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "  # Zero gradients, backward pass, and update weights\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "# Network 2\n",
    "# Define the model architecture\n",
    "# Activation function: sigmoid\n",
    "# Arhitecture: 2 input neuron, 3 hidden neurons, 2 output neuron\n",
    "# Loss function: Mean squared error\n",
    "model2 = nn.Sequential(OrderedDict([\n",
    "          ('fc1', nn.Linear(2, 3)),\n",
    "          ('sigmoid1', nn.Sigmoid()),\n",
    "          ('fc2', nn.Linear(3, 2)),\n",
    "          ('linear1', nn.Identity())\n",
    "        ]))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(1000):\n",
    "  # Forward pass\n",
    "  y_pred = model2(x_train)\n",
    "\n",
    "  # Compute loss\n",
    "  loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "  # Zero gradients, backward pass, and update weights\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "# Network 3\n",
    "# Define the model architecture\n",
    "# Activation function: ReLU\n",
    "# Arhitecture: 2 input neurons, 2 hidden neurons, 2 output neurons\n",
    "# Loss functions: Mean Squared error\n",
    "model3 = nn.Sequential(OrderedDict([\n",
    "          ('fc1', nn.Linear(2, 3)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2', nn.Linear(3, 2)),\n",
    "          ('linear1', nn.Sigmoid())\n",
    "        ]))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model3.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(1000):\n",
    "  # Forward pass\n",
    "  y_pred = model3(x_train)\n",
    "\n",
    "  # Compute loss\n",
    "  loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "  # Zero gradients, backward pass, and update weights\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "# Evaluate the models and get the best one\n",
    "x_test = torch.Tensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_test = torch.Tensor([[0, 0], [0, 1], [0, 1], [1, 0]])\n",
    "\n",
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "i = 1\n",
    "best_network = -1\n",
    "for model in [model1, model2, model3]:\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x_test)\n",
    "        test_loss = loss_fn(y_pred, y_test).item()\n",
    "        y_pred = torch.round(y_pred)\n",
    "        accuracy = (y_pred == y_test).sum().item() / (len(y_test) * len(y_test[0]))\n",
    "        \n",
    "    print(f'Network {i} ')\n",
    "    print('Test loss: {:.2f}'.format(test_loss))\n",
    "    print('Accuracy: {:.2f}%'.format(accuracy*100))\n",
    "    print('Predictions:', y_pred.flatten().tolist())\n",
    "    print('\\n')\n",
    "    if test_loss < best_loss:\n",
    "        best_model = model\n",
    "        best_loss = test_loss\n",
    "        best_network = i\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(f'Network {best_network}: ')\n",
    "# Display the weights for each layer of the best model\n",
    "for name, param in best_model.named_parameters():\n",
    "    print(name, param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a890e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
